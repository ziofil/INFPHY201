{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://licensebuttons.net/l/by-nc-sa/3.0/88x31.png) Filippo Miatto (2024) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 1: Numerical tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. A bit of numpy\n",
    "\n",
    "`Numpy` is one of the most popular python libraries for numerical math.\n",
    "\n",
    "The most useful tool that I want to teach you is the function `np.einsum()`, but before we get there let's learn about arrays and axes. An array is a generalization of vectors and matrices. For us an array is a collection of numbers, where each number is identified by a set of integer coordinates.\n",
    "\n",
    "The meaning that we attribute to the array depends on what we will use it for. Here's a couple examples:\n",
    "\n",
    "1. A complex array with shape `(n,)` can be interpreted as a vector $v \\in \\mathbb{C}^n$.\n",
    "\n",
    "2. A complex array with shape `(m,n)` can be interpreted as a rectangular matrix, i.e. a map $M : \\mathbb{C}^n\\rightarrow \\mathbb{C}^m$, but it can also be interpreted as a vector $v \\in \\mathbb{C}^m\\otimes \\mathbb{C}^n$.\n",
    "\n",
    "A generic array is simply a collection of numbers with multiple indices: $T_{ijklmn\\dots}$, whose meaning depends on the context.\n",
    "\n",
    "The number of indices is called the _order_ of the array, so column vectors are order-1 arrays, matrices are order-2 arrays etc...\n",
    "\n",
    "Each index has a dimension (i.e. the number of distinct integer values that it can have), and the dimension does not have to be the same for all the indices, e.g. a rectangular matrix has two indices of different dimensions. If we call $d(j)$ the dimension of index $j$, then an array $T_{j_1,\\dots,j_r}$ of order $r$ contains $d(j_1)\\times d(j_2)\\times\\dots\\times d(j_r)$ numbers, and so the total size of an array scales more or less exponentially with the number of indices, i.e. with the order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy provides powerful tools for handling arrays of any dimension. Here are key concepts for working with arrays:\n",
    "\n",
    "- `shape`: A tuple containing the size of each dimension of the array. For example, a 2x3 matrix has shape (2,3). The length of the shape tuple gives the number of dimensions (order) of the array.\n",
    "\n",
    "- `np.newaxis` (or `None`): Creates a new dimension of size 1 in an array. Useful for broadcasting and reshaping operations. Example: `v[:, None]` converts a vector into a column matrix with a single column.\n",
    "\n",
    "- `Ellipsis` (`...`): A placeholder for any number of dimensions. Handy when you don't know the exact number of dimensions or want to keep trailing dimensions unchanged. Example: `T[..., 0]` selects the first element along the last dimension.\n",
    "\n",
    "- `slice`: Provides efficient views into arrays without copying data. Syntax: `array[start:stop:step]`. Numpy creates a view by adjusting strides rather than copying memory.\n",
    "\n",
    "- `Broadcasting`: Automatically aligns arrays of different shapes for operations. Rules: 1) Dimensions must match or be 1, 2) Missing dimensions are treated as 1. Example: `(3,)` array can broadcast with `(3,3)` matrix.\n",
    "\n",
    "- `strides`: Memory layout information that determines how to traverse the array. Each dimension has a stride (bytes to skip). Understanding strides helps optimize memory access and enables advanced operations.\n",
    "\n",
    "- `reshape`: Reorganizes array dimensions without changing data. Can split or combine dimensions. Example: `(6,)` â†’ `(2,3)`. Use `-1` to automatically calculate a dimension size.\n",
    "\n",
    "- `transpose`: Reorders dimensions of an array. Crucial for tensor operations and matrix manipulations. Example: `T.transpose(2,0,1)` reorders dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding a second index. New shape of the tensor is (3, 1):\n",
      " [[1]\n",
      " [2]\n",
      " [3]] \n",
      "\n",
      "Adding a new first index. New shape of the tensor is (1, 3):\n",
      " [[1 2 3]] \n",
      "\n",
      "Adding a second and third index. New shape of the tensor is (3, 1, 1):\n",
      " [[[1]]\n",
      "\n",
      " [[2]]\n",
      "\n",
      " [[3]]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# using None for new axes\n",
    "v = np.array([1,2,3]) # a vector\n",
    "\n",
    "v1 = v[:, None]\n",
    "print(f'Adding a second index. New shape of the tensor is {v1.shape}:\\n', v1, '\\n')\n",
    "\n",
    "v2 = v[None, :]\n",
    "print(f'Adding a new first index. New shape of the tensor is {v2.shape}:\\n', v2, '\\n')\n",
    "\n",
    "v3 = v[:, None, None]\n",
    "print(f'Adding a second and third index. New shape of the tensor is {v3.shape}:\\n', v3, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "broadcasting along index 1 (rows):\n",
      "[[1. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [1. 2. 3.]] \n",
      "\n",
      "broadcasting along index 0 (columns):\n",
      "[[1. 1. 1.]\n",
      " [2. 2. 2.]\n",
      " [3. 3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "# using new axes for broadcasting\n",
    "\n",
    "v = np.array([1,2,3]) # a 3-dim vector\n",
    "m = np.ones((3,3)) # a 3x3 matrix of ones\n",
    "\n",
    "# compare:\n",
    "\n",
    "print('broadcasting along index 1 (rows):')\n",
    "print(v[None, :] * m, '\\n')\n",
    "\n",
    "print('broadcasting along index 0 (columns):')\n",
    "print(v[:, None] * m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3, 4, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage of ellipsis\n",
    "\n",
    "T = np.zeros((2,3,4,5)) # tensor of shape (2,3,4,5)\n",
    "T[None, ...].shape  # adding an index of size 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 `np.einsum()`: the swiss army knife of array operations\n",
    "\n",
    "`np.einsum()` (short for Einstein summation) is an incredibly powerful and versatile function in NumPy for performing a wide array of tensor operations. It can express many common operations like dot products, outer products, matrix multiplication, transpositions, traces, and sums over specific axes, as well as complex multi-dimensional contractions, all using a concise and expressive string-based notation.\n",
    "\n",
    "The function's first argument is a string that defines the operation. This string uses letters to represent the indices of the input arrays and specifies how these indices should be combined or permuted. Subsequent arguments are the NumPy arrays themselves:\n",
    "\n",
    "```python\n",
    "np.einsum('string goes here', arrays, go, here)\n",
    "```\n",
    "\n",
    "The fundamental rule of Einstein summation is:\n",
    "\n",
    "$$\n",
    "\\mathbf{Repeated\\ indices\\ in\\ the\\ input\\ specification\\ are\\ summed\\ over.}\n",
    "$$\n",
    "\n",
    "When an index is repeated (appearing in at least two input operands or twice in a single operand), it implies a summation over all possible values of that index. This process is often called \"contracting\" the index.\n",
    "\n",
    "The string specification typically has two parts, separated by an arrow `->`:\n",
    "-   The part **before** `->` defines the indices of the input arrays. Each array's indices are specified as a string of letters, and multiple input arrays are separated by commas (e.g., `'ij,jk'`).\n",
    "-   The part **after** `->` defines the indices of the output array (e.g., `'ik'`).\n",
    "\n",
    "If the `->` and the output indices are omitted (e.g., `'ij,jk'`), `np.einsum` infers the output: it will consist of the unrepeated input indices from the input specification, sorted alphabetically. However, explicitly defining the output using `->` is generally clearer, more robust, and recommended for precise control.\n",
    "\n",
    "Let's explore some key examples to understand its power:\n",
    "\n",
    "### Matrix Multiplication\n",
    "Standard matrix multiplication $C = MN$ is defined as $C_{ik} = \\sum_j M_{ij}N_{jk}$.\n",
    "The index `j` is repeated in the input terms $M_{ij}$ and $N_{jk}$, so it is summed over (contracted). The remaining indices, `i` from $M$ and `k` from $N$, form the indices of the resulting matrix $C_{ik}$.\n",
    "\n",
    "Matrix multiplication between, say, 4 matrices is\n",
    "$$\n",
    "(MNPQ)_{im} = \\sum_{jkl} M_{ij}N_{jk}P_{kl}Q_{lm}\n",
    "$$\n",
    "\n",
    "With `np.einsum` this would be:\n",
    "\n",
    "```python\n",
    "np.einsum('j,jklm,jk,l -> m', M, N, P, Q)\n",
    "```\n",
    "\n",
    "### Transposition\n",
    "The string after the arrow allows us to do some final rearranging of the indices, like a transposition:\n",
    "\n",
    "$$\n",
    "(MN)^T_{ki} = (MN)_{ik}\n",
    "$$\n",
    "With `np.einsum` this would be:\n",
    "\n",
    "```python\n",
    "np.einsum('ij,jk -> ki', M, N) # notice: ki and not ik\n",
    "```\n",
    "\n",
    "### Traces\n",
    "If we repeat an index belonging to the same tensor, we compute a trace:\n",
    "\n",
    "$$\n",
    "Tr(M) = \\sum_{i} M_{ii}\n",
    "$$\n",
    "With `np.einsum` this would be:\n",
    "\n",
    "```python\n",
    "np.einsum('ii', M)\n",
    "```\n",
    "\n",
    "### Tensor products (i.e. outer products)\n",
    "Outer products are the opposite of inner products, i.e. we simply juxtapose indices:\n",
    "\n",
    "E.g. with vectors:\n",
    "$$\n",
    "(\\mathbf{v}\\otimes \\mathbf{w})_{ij} = v_{i}w_{j}\n",
    "$$\n",
    "With `np.einsum` this would be:\n",
    "\n",
    "```python\n",
    "np.einsum('i,j -> ij', v, w)\n",
    "```\n",
    "\n",
    "Or with matrices:\n",
    "$$\n",
    "(M\\otimes N)_{ijkl} = M_{ij}N_{kl}\n",
    "$$\n",
    "With `np.einsum` this would be:\n",
    "\n",
    "```python\n",
    "np.einsum('ij,kl -> ijkl', M, N)\n",
    "```\n",
    "\n",
    "Note on the outer product; often it is a bad idea to \"actually\" calculate an outer product. For better performance, try to keep the parts separated unless the values of the outer product are absolutely needed. Chances are that the two parts might shed indices and get smaller by contracting with other tensors, as the calculation progresses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity 1: Hilbert-Schmidt inner product\n",
    "\n",
    "The Hilbert-Schmidt inner product is an inner product between complex matrices and it is defined as follows:\n",
    "\n",
    "$$\n",
    "\\langle M, N\\rangle = Tr(M^\\dagger N)\n",
    "$$\n",
    "\n",
    "where $M^\\dagger$ means we transpose and complex-conjugate $M$.\n",
    "\n",
    "- `v1`: implement the formula as is written above, using `np.matmul`, `np.trace` and `np.conj` to compute the conjugate\n",
    "- `v2`: implement the formula using `np.einsum` and `np.conj`\n",
    "- `v3`: implement the formula in a more efficient way than `v1` without using `np.einsum`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v1\n",
    "def HS_inner_product(M, N):\n",
    "    return np.trace(np.matmul(np.transpose(np.conj(M)), N))\n",
    "\n",
    "# v2\n",
    "def HS_inner_product(M, N):\n",
    "    return np.einsum('ji,ji', np.conj(M), N)\n",
    "\n",
    "# v3\n",
    "def HS_inner_product(M, N):\n",
    "    return np.sum(np.conj(M) * N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how numpy's syntax allows us to write the inner product in a way that can apply to tensors of any (matching) shape but still look like the formula for the inner product between two vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity 2: Multiply by a diagonal matrix\n",
    "\n",
    "Consider the product between three matrices: $ABC$, where $B$ is a diagonal matrix. This happens all the time when we consider eigenvalue decomposition or a singular value decomposition, where the matrix in the middle is diagonal.\n",
    "\n",
    "- `v1`: implement this product as written above (treat $B$ as if it were any matrix) using `np.einsum`\n",
    "- `v2`: implement this product in a more efficient way (use the fact that $B$ is diagonal) using `np.einsum` \n",
    "- `v3`: implement this product with `np.einsum` and `np.diag(B)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v1\n",
    "def prod_v1(A, B, C):\n",
    "    return np.einsum('ij,jk,kl -> il', A, B, C) # 3 matrices\n",
    "# v2\n",
    "def prod_v2(A, B, C):\n",
    "    return np.einsum('ij,jj,jl -> il', A, B, C) # B is diagonal\n",
    "# v3\n",
    "def prod_v3(A, B, C):\n",
    "    return np.einsum('ij,j,jl -> il', A, np.diag(B), C) # only using the diagonal of B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[109]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqernel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m profile\n\u001b[32m      4\u001b[39m A,B,C = np.random.random((\u001b[32m3\u001b[39m,\u001b[32m20\u001b[39m,\u001b[32m20\u001b[39m)) \u001b[38;5;66;03m# each matrix is 20 x 20\u001b[39;00m\n\u001b[32m      5\u001b[39m profile(prod_v1, A, B, C)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/INFPHY201/qernel/utils.py:27\u001b[39m\n\u001b[32m     22\u001b[39m         signal.alarm(\u001b[32m0\u001b[39m)  \u001b[38;5;66;03m# Ensure alarm is disabled\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Matplotlib\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# IPython clear_output (for the live_plot function)\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clear_output\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "from qernel.utils import profile\n",
    "\n",
    "\n",
    "A,B,C = np.random.random((3,20,20)) # each matrix is 20 x 20\n",
    "profile(prod_v1, A, B, C)\n",
    "profile(prod_v2, A, B, C)\n",
    "profile(prod_v3, A, B, C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
